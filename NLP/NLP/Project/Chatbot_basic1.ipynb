{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4660b0f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tkinter (from versions: none)\n",
      "ERROR: No matching distribution found for tkinter\n"
     ]
    }
   ],
   "source": [
    "#pip install tkinter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7341efe3",
   "metadata": {},
   "source": [
    "# First trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7356ca3d",
   "metadata": {},
   "source": [
    "from this link\n",
    "https://www.analyticsvidhya.com/blog/2021/07/build-a-simple-chatbot-using-python-and-nltk/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c2811d",
   "metadata": {},
   "source": [
    "Using hardcoded strings for user input to reply to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9b7711ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "root = Tk()\n",
    "root.title(\"Chatbot\")\n",
    "def send():\n",
    "    send = \"You -> \"+e.get()\n",
    "    txt.insert(END, \"\\n\"+send)\n",
    "    user = e.get().lower()\n",
    "    if(user == \"hello\"):\n",
    "        txt.insert(END, \"n\" + \"Bot -> Hi\")\n",
    "    elif(user == \"hi\" or user == \"hii\" or user == \"hiiii\"):\n",
    "        txt.insert(END, \"\\n\" + \"Bot -> Hello\")\n",
    "    elif(e.get() == \"how are you\"):\n",
    "        txt.insert(END, \"\\n\" + \"Bot -> fine! and you\")\n",
    "    elif(user == \"fine\" or user == \"i am good\" or user == \"i am doing good\"):\n",
    "        txt.insert(END, \"\\n\" + \"Bot -> Great! how can I help you.\")\n",
    "    else:\n",
    "        txt.insert(END, \"\\n\" + \"Bot -> Sorry! I didn't get you\")\n",
    "    e.delete(0, END)\n",
    "txt = Text(root)\n",
    "txt.grid(row=0, column=0, columnspan=2)\n",
    "e = Entry(root, width=100)\n",
    "e.grid(row=1, column=0)\n",
    "send = Button(root, text=\"Send\", command=send).grid(row=1, column=1)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec65e0e",
   "metadata": {},
   "source": [
    "# Second trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74979f7a",
   "metadata": {},
   "source": [
    "Using Regex for matching the user input to crresponding pair of QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ef68de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.chat.util import Chat, reflections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3169b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    [\n",
    "        r\"my name is (.*)\",\n",
    "        [\"Hello %1, How are you today ?\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"hi|hey|hello\",\n",
    "        [\"Hello\", \"Hey there\",]\n",
    "    ], \n",
    "    [\n",
    "        r\"what is your name ?\",\n",
    "        [\"I am a bot created by Analytics Vidhya. you can call me crazy!\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"how are you ?\",\n",
    "        [\"I'm doing goodnHow about You ?\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"sorry (.*)\",\n",
    "        [\"Its alright\",\"Its OK, never mind\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"I am fine\",\n",
    "        [\"Great to hear that, How can I help you?\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"i'm (.*) doing good\",\n",
    "        [\"Nice to hear that\",\"How can I help you?:)\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*) age?\",\n",
    "        [\"I'm a computer program dudenSeriously you are asking me this?\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"what (.*) want ?\",\n",
    "        [\"Make me an offer I can't refuse\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*) created ?\",\n",
    "        [\"Raghav created me using Python's NLTK library \",\"top secret ;)\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*) (location|city) ?\",\n",
    "        ['Indore, Madhya Pradesh',]\n",
    "    ],\n",
    "    [\n",
    "        r\"how is weather in (.*)?\",\n",
    "        [\"Weather in %1 is awesome like always\",\"Too hot man here in %1\",\"Too cold man here in %1\",\"Never even heard about %1\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"i work in (.*)?\",\n",
    "        [\"%1 is an Amazing company, I have heard about it. But they are in huge loss these days.\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*)raining in (.*)\",\n",
    "        [\"No rain since last week here in %2\",\"Damn its raining too much here in %2\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"how (.*) health(.*)\",\n",
    "        [\"I'm a computer program, so I'm always healthy \",]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*) (sports|game) ?\",\n",
    "        [\"I'm a very big fan of Football\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"who (.*) sportsperson ?\",\n",
    "        [\"Messy\",\"Ronaldo\",\"Roony\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"who (.*) (moviestar|actor)?\",\n",
    "        [\"Brad Pitt\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"i am looking for online guides and courses to learn data science, can you suggest?\",\n",
    "        [\"Crazy_Tech has many great articles with each step explanation along with code, you can explore\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"quit\",\n",
    "        [\"BBye take care. See you soon :) \",\"It was nice talking to you. See you soon :)\"]\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187a77f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def chat():\n",
    "    print(\"Hi! I am a chatbot created by Analytics Vidhya for your service\")\n",
    "    chat = Chat(pairs, reflections)\n",
    "    chat.converse()\n",
    "#initiate the conversation\n",
    "if __name__ == \"__main__\":\n",
    "    chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328db6c6",
   "metadata": {},
   "source": [
    "# Third trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f7c184",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/building-a-chatbot-in-python-the-beginners-guide-2743ad2b4851"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11331070",
   "metadata": {},
   "source": [
    "Using hardcoded mappings to transform the input of the user to one of the predefined question pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d82c90ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOT: What do you want me to call you?\n",
      "Esraa\n"
     ]
    }
   ],
   "source": [
    "print(\"BOT: What do you want me to call you?\")\n",
    "user_name = input()\n",
    "bot_template = \"BOT : {0}\"\n",
    "user_template = user_name + \" : {0}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b61313cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converstion dictionaries\n",
    "name = \"Funny Bot 101\" \n",
    "weather = \"rainy\" \n",
    "mood = \"Happy\"\n",
    "responses = { \n",
    "\"what's your name?\": [ \n",
    "\"They call me {0}\".format(name), \n",
    "\"I usually go by {0}\".format(name), \n",
    "\"My name is the {0}\".format(name) ],\n",
    "\"what's today's weather?\": [ \n",
    "\"The weather is {0}\".format(weather), \n",
    "\"It's {0} today\".format(weather), \n",
    "\"Let me check, it looks {0} today\".format(weather) ],\n",
    "\"Are you a robot?\": [ \n",
    "\"What do you think?\", \n",
    "\"Maybe yes, maybe no!\", \n",
    "\"Yes, I am a robot with human feelings.\", ],\n",
    "\"how are you?\": [ \n",
    "\"I am feeling {0}\".format(mood), \n",
    "\"{0}! How about you?\".format(mood), \n",
    "\"I am {0}! How about yourself?\".format(mood), ],\n",
    "\"\": [ \n",
    "\"Hey! Are you there?\", \n",
    "\"What do you mean by saying nothing?\", \n",
    "\"Sometimes saying nothing tells a lot :)\", ],\n",
    "\"default\": [\n",
    "\"this is a default message\"] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b22e916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def respond(message):\n",
    "    if message in responses: \n",
    "        bot_message = random.choice(responses[message])\n",
    "    else: \n",
    "        bot_message = random.choice(responses[\"default\"])\n",
    "    return bot_message\n",
    "\n",
    "def related(x_text): \n",
    "    if \"name\" in x_text: \n",
    "        y_text = \"what's your name?\"\n",
    "    elif \"weather\" in x_text: \n",
    "        y_text = \"what's today's weather?\"\n",
    "    elif \"robot\" in x_text: \n",
    "        y_text = \"are you a robot?\"\n",
    "    elif \"how are\" in x_text: \n",
    "        y_text = \"how are you?\"\n",
    "    else: \n",
    "        y_text = \"\"\n",
    "    return y_text\n",
    "\n",
    "def send_message(message): \n",
    "    print(user_template.format(message)) \n",
    "    response = respond(message) \n",
    "    print(bot_template.format(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2658f68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how are you\n",
      "Esraa : how are you?\n",
      "BOT : I am Happy! How about yourself?\n",
      "happy as well\n",
      "Esraa : \n",
      "BOT : What do you mean by saying nothing?\n",
      "nothing\n",
      "Esraa : \n",
      "BOT : What do you mean by saying nothing?\n",
      "what's your name\n",
      "Esraa : what's your name?\n",
      "BOT : They call me Funny Bot 101\n",
      "exit\n",
      "Esraa : \n",
      "BOT : Sometimes saying nothing tells a lot :)\n"
     ]
    }
   ],
   "source": [
    "while 1: \n",
    "    my_input = input() \n",
    "    if my_input == \"exit\" or my_input == \"stop\": \n",
    "        break\n",
    "    my_input = my_input.lower() \n",
    "    related_text = related(my_input) \n",
    "    send_message(related_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b79e890",
   "metadata": {},
   "source": [
    "# Fourth trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb775c77",
   "metadata": {},
   "source": [
    "https://online.datasciencedojo.com/blogs/rule-based-chatbot-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e6d702",
   "metadata": {},
   "source": [
    "A nice implmentation using regex and synonms to answer user questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3fef302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules\n",
    "import re\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2a9d154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hello': {'howdy', 'how do you do', 'hello', 'hi', 'hullo'}, 'timings': {'timing', 'time', 'clock'}}\n"
     ]
    }
   ],
   "source": [
    "# Building a list of Keywords\n",
    "\n",
    "list_words=['hello','timings']\n",
    "list_syn={}\n",
    "\n",
    "for word in list_words:\n",
    "    synonyms=[]\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lem in syn.lemmas():\n",
    "            # Remove any special characters from synonym strings\n",
    "            lem_name = re.sub('[^a-zA-Z0-9 \\n\\.]', ' ', lem.name())\n",
    "            synonyms.append(lem_name)\n",
    "    list_syn[word]=set(synonyms)\n",
    "\n",
    "\n",
    "print (list_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbeceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Welcome, I'm Emo chatbot.\")\n",
    "# While loop to run the chatbot indefinetely\n",
    "while (True):  \n",
    "    # Takes the user input and converts all characters to lowercase\n",
    "    user_input = input().lower()\n",
    "    # Defining the Chatbot's exit condition\n",
    "    if user_input == 'quit': \n",
    "        print (\"Thank you for chatting with me.\")\n",
    "        break    \n",
    "\n",
    "    matched_intent = None \n",
    "    for intent,pattern in keywords_dict.items():\n",
    "        # Using the regular expression search function to look for keywords in user input\n",
    "        if re.search(pattern, user_input): \n",
    "            # if a keyword matches, select the corresponding intent from the keywords_dict dictionary\n",
    "            matched_intent=intent  \n",
    "    # The fallback intent is selected by default\n",
    "    key='fallback' \n",
    "    if matched_intent in responses:\n",
    "        # If a keyword matches, the fallback intent is replaced by the matched intent as the key for the responses dictionary\n",
    "        key = matched_intent \n",
    "\n",
    "    # The chatbot prints the response that matches the selected intent\n",
    "    print (responses[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf60aae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'greet': re.compile('.*\\\\bhowdy\\\\b.*|.*\\\\bhow do you do\\\\b.*|.*\\\\bhello\\\\b.*|.*\\\\bhi\\\\b.*|.*\\\\bhullo\\\\b.*'), 'timings': re.compile('.*\\\\btiming\\\\b.*|.*\\\\btime\\\\b.*|.*\\\\bclock\\\\b.*')}\n"
     ]
    }
   ],
   "source": [
    "# Building dictionary of Intents & Keywords\n",
    "keywords={}\n",
    "keywords_dict={}\n",
    "\n",
    "# Defining a new key in the keywords dictionary\n",
    "keywords['greet']=[]\n",
    "\n",
    "\n",
    "# Populating the values in the keywords dictionary with synonyms of keywords formatted with RegEx metacharacters \n",
    "for synonym in list(list_syn['hello']):\n",
    "    keywords['greet'].append('.*\\\\b'+synonym+'\\\\b.*')\n",
    "# Defining a new key in the keywords dictionary\n",
    "\n",
    "keywords['timings']=[]\n",
    "# Populating the values in the keywords dictionary with synonyms of keywords formatted with RegEx metacharacters \n",
    "for synonym in list(list_syn['timings']):\n",
    "    keywords['timings'].append('.*\\\\b'+synonym+'\\\\b.*')\n",
    "\n",
    "for intent, keys in keywords.items():\n",
    "    # Joining the values in the keywords dictionary with the OR (|) operator updating them in keywords_dict dictionary\n",
    "    keywords_dict[intent]=re.compile('|'.join(keys))\n",
    "\n",
    "print (keywords_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7c21ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a dictionary of responses\n",
    "\n",
    "responses={\n",
    "    'greet':'Hello! How can I help you?',\n",
    "    'timings':'We are open from 9AM to 5PM, Monday to Friday. We are closed on weekends and public holidays.',\n",
    "    'fallback':'I dont quite understand. Could you repeat that?',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d0f2abb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to MyBank. How may I help you?\n",
      "Hello\n",
      "Hello! How can I help you?\n",
      "when do you open?\n",
      "I dont quite understand. Could you repeat that?\n",
      "what time do you open?\n",
      "We are open from 9AM to 5PM, Monday to Friday. We are closed on weekends and public holidays.\n",
      "ok thanks\n",
      "I dont quite understand. Could you repeat that?\n",
      "quit\n",
      "Thank you for visiting.\n"
     ]
    }
   ],
   "source": [
    "print (\"Welcome to MyBank. How may I help you?\")\n",
    "# While loop to run the chatbot indefinetely\n",
    "while (True):  \n",
    "    # Takes the user input and converts all characters to lowercase\n",
    "    user_input = input().lower()\n",
    "    # Defining the Chatbot's exit condition\n",
    "    if user_input == 'quit': \n",
    "        print (\"Thank you for visiting.\")\n",
    "        break    \n",
    "\n",
    "    matched_intent = None \n",
    "    for intent,pattern in keywords_dict.items():\n",
    "        # Using the regular expression search function to look for keywords in user input\n",
    "        if re.search(pattern, user_input): \n",
    "            # if a keyword matches, select the corresponding intent from the keywords_dict dictionary\n",
    "            matched_intent=intent  \n",
    "    # The fallback intent is selected by default\n",
    "    key='fallback' \n",
    "    if matched_intent in responses:\n",
    "        # If a keyword matches, the fallback intent is replaced by the matched intent as the key for the responses dictionary\n",
    "        key = matched_intent \n",
    "\n",
    "    # The chatbot prints the response that matches the selected intent\n",
    "    print (responses[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60e5073",
   "metadata": {},
   "source": [
    "# Fifth trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c8c8d5",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2022/05/a-complete-guide-on-chatbot-development-using-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2044510",
   "metadata": {},
   "source": [
    "Based on DL model to predict the intent of the user, seems ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2acfe053",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\esraa\\anaconda3\\envs\\nlp_py_3\\lib\\site-packages (3.7)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.9.1-cp39-cp39-win_amd64.whl (444.0 MB)\n",
      "Requirement already satisfied: keras in c:\\users\\esraa\\anaconda3\\envs\\nlp_py_3\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\esraa\\anaconda3\\envs\\nlp_py_3\\lib\\site-packages (from nltk) (2022.6.2)\n",
      "Requirement already satisfied: click in c:\\users\\esraa\\anaconda3\\envs\\nlp_py_3\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\esraa\\anaconda3\\envs\\nlp_py_3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tqdm in c:\\users\\esraa\\anaconda3\\envs\\nlp_py_3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.26.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting flatbuffers<2,>=1.12\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\esraa\\anaconda3\\envs\\nlp_py_3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\esraa\\anaconda3\\envs\\nlp_py_3\\lib\\site-packages (from tensorflow) (1.22.3)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.48.0-cp39-cp39-win_amd64.whl (3.6 MB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.4-cp39-cp39-win_amd64.whl (895 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.14.1-cp39-cp39-win_amd64.whl (35 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "  Using cached tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.7.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\esraa\\anaconda3\\envs\\nlp_py_3\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\esraa\\anaconda3\\envs\\nlp_py_3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\esraa\\anaconda3\\envs\\nlp_py_3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Using cached tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-14.0.1-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\esraa\\anaconda3\\envs\\nlp_py_3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\esraa\\anaconda3\\envs\\nlp_py_3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.28.0)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.1-py3-none-any.whl (232 kB)\n",
      "     ------------------------------------ 232.4/232.4 kB 945.3 kB/s eta 0:00:00\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.9.1-py2.py3-none-any.whl (167 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\esraa\\anaconda3\\envs\\nlp_py_3\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\esraa\\anaconda3\\envs\\nlp_py_3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-4.12.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\esraa\\anaconda3\\envs\\nlp_py_3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\esraa\\anaconda3\\envs\\nlp_py_3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\esraa\\anaconda3\\envs\\nlp_py_3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\esraa\\anaconda3\\envs\\nlp_py_3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\esraa\\anaconda3\\envs\\nlp_py_3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow) (2.1.1)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.8.1-py3-none-any.whl (5.6 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: termcolor, tensorboard-plugin-wit, pyasn1, libclang, flatbuffers, zipp, wrapt, werkzeug, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyasn1-modules, protobuf, opt-einsum, oauthlib, keras-preprocessing, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, importlib-metadata, google-auth, markdown, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-1.2.0 astunparse-1.6.3 cachetools-5.2.0 flatbuffers-1.12 gast-0.4.0 google-auth-2.9.1 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.48.0 h5py-3.7.0 importlib-metadata-4.12.0 keras-preprocessing-1.1.2 libclang-14.0.1 markdown-3.4.1 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 termcolor-1.1.0 werkzeug-2.2.1 wrapt-1.14.1 zipp-3.8.1\n"
     ]
    }
   ],
   "source": [
    "#pip install nltk tensorflow keras \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6add1378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "853be29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\esraa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\esraa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7ac8871",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_words=[]\n",
    "classes = []\n",
    "doc = []\n",
    "ignoring_words = ['?', '!']\n",
    "data_file = open('intents_file.json').read()\n",
    "intents = json.loads(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9172e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        w = nltk.word_tokenize(pattern) #tokenizing\n",
    "        tokenized_words.extend(w)\n",
    "        doc.append((w, intent['tag']))\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f8d4f7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['goodbye', 'greetings', 'support', 'thanks']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1dacc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(words.lower()) for words in tokenized_words if w not in ignoring_words] #lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9098110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_words = sorted(list(set(lemmatized_words))) \n",
    "classes = sorted(list(set(classes)))\n",
    "pickle.dump(lemmatized_words,open('lem_words.pkl','wb'))\n",
    "pickle.dump(classes,open('classes.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cebeebfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esraa\\AppData\\Local\\Temp\\ipykernel_25368\\385031765.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  training = np.array(training_data)\n"
     ]
    }
   ],
   "source": [
    "training_data = []\n",
    "empty_array = [0] * len(classes)\n",
    "\n",
    "for d in doc:\n",
    "    bag_of_words = []\n",
    "    pattern = d[0]\n",
    "    pattern = [lemmatizer.lemmatize(word.lower()) for word in pattern]\n",
    "    for w in lemmatized_words:\n",
    "        bag_of_words.append(1) if w in pattern else bag_of_words.append(0)\n",
    "    output_row = list(empty_array)\n",
    "    output_row[classes.index(d[1])] = 1\n",
    "    training_data.append([bag_of_words, output_row])\n",
    "\n",
    "random.shuffle(training_data)\n",
    "training = np.array(training_data)\n",
    "x_train = list(training[:,0])\n",
    "y_train = list(training[:,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04a8163",
   "metadata": {},
   "source": [
    "## model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2048e5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esraa\\anaconda3\\envs\\NLP_PY_3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step - loss: 1.4210 - accuracy: 0.2105\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.3136 - accuracy: 0.3684\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2570 - accuracy: 0.4211\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3776 - accuracy: 0.2105\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.2929 - accuracy: 0.5263\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2584 - accuracy: 0.4211\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1828 - accuracy: 0.5263\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0774 - accuracy: 0.6316\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0986 - accuracy: 0.6316\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9597 - accuracy: 0.5263\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0174 - accuracy: 0.6842\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7959 - accuracy: 0.7368\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9265 - accuracy: 0.6842\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7425 - accuracy: 0.8421\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6146 - accuracy: 0.7895\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7709 - accuracy: 0.6842\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7131 - accuracy: 0.6842\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6000 - accuracy: 0.7368\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5237 - accuracy: 0.8421\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6563 - accuracy: 0.7368\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.9474\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7895\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2792 - accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3584 - accuracy: 0.8421\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3256 - accuracy: 0.8947\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2743 - accuracy: 0.9474\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8421\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3141 - accuracy: 0.9474\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2629 - accuracy: 0.8947\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2138 - accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2607 - accuracy: 0.8947\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3224 - accuracy: 0.8421\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2673 - accuracy: 0.9474\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1796 - accuracy: 0.9474\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1431 - accuracy: 0.9474\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1911 - accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1188 - accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1261 - accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1574 - accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2368 - accuracy: 0.9474\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0471 - accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1384 - accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2367 - accuracy: 0.8947\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1566 - accuracy: 0.9474\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3278 - accuracy: 0.9474\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2003 - accuracy: 0.9474\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1810 - accuracy: 0.9474\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0684 - accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0546 - accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1228 - accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1027 - accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1537 - accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0447 - accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9474\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1101 - accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1304 - accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0997 - accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1249 - accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1082 - accuracy: 0.9474\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0846 - accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0829 - accuracy: 0.9474\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0733 - accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0554 - accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1040 - accuracy: 0.9474\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1076 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0283 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1519 - accuracy: 0.9474\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0481 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1669 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0818 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0251 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0743 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9474\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0359 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1657 - accuracy: 0.8947\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.9474\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0260 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0324 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0292 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1408 - accuracy: 0.8947\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0885 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.9474\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2010 - accuracy: 0.9474\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0280 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1988 - accuracy: 0.9474\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0766 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0862 - accuracy: 0.9474\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0262 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.9474\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0339 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0805 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7.4485e-04 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "bot_model = Sequential()\n",
    "bot_model.add(Dense(128, input_shape=(len(x_train[0]),), activation='relu'))\n",
    "bot_model.add(Dropout(0.5))\n",
    "bot_model.add(Dense(64, activation='relu'))\n",
    "bot_model.add(Dropout(0.5))\n",
    "bot_model.add(Dropout(0.25))\n",
    "bot_model.add(Dense(len(y_train[0]), activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "bot_model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "hist = bot_model.fit(x_train, y_train, epochs=200, batch_size=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fcdae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_model.save('chatbot_model.h5', hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeca60dd",
   "metadata": {},
   "source": [
    "## Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "930d8525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "from keras.models import load_model\n",
    "import random\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72d5676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "intents_file = json.loads(open('intents_file.json').read())\n",
    "lem_words = pickle.load(open('lem_words.pkl','rb'))\n",
    "classes = pickle.load(open('classes.pkl','rb'))\n",
    "bot_model = load_model('chatbot_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ccec260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(word.lower()) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "083c5b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_ow(text, words, show_details=True):\n",
    "    sentence_words = cleaning(text)\n",
    "    bag_of_words = [0]*len(words) \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s: \n",
    "                bag_of_words[i] = 1\n",
    "    return (np.array(bag_of_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7cadac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_prediction(sentence, model):\n",
    "    p = bag_ow(sentence, lem_words,show_details=False)\n",
    "    result = bot_model.predict(np.array([p]))[0]\n",
    "    ER_THRESHOLD = 0.30\n",
    "    f_results = [[i,r] for i,r in enumerate(result) if r > ER_THRESHOLD]\n",
    "    f_results.sort(key=lambda x: x[1], reverse=True)\n",
    "    intent_prob_list = []\n",
    "    \n",
    "    for i in f_results:\n",
    "        intent_prob_list.append({\"intent\": i[0], \"probability\": str(i[1])})\n",
    "    return intent_prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e7628c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getbotResponse(ints, intents):\n",
    "    #print(ints)\n",
    "    #print(classes[ints[0]['intent']])\n",
    "    tag = classes[ints[0]['intent']]\n",
    "    print(tag)\n",
    "    intents_list = intents['intents']\n",
    "    for intent in intents_list:\n",
    "        if(intent['tag']== tag):\n",
    "            result = random.choice(intent['responses'])\n",
    "            break\n",
    "    return result\n",
    "def bot_response(text):\n",
    "    ints = class_prediction(text, bot_model)\n",
    "    response = getbotResponse(ints, intents)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8ae76f1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You : Hi\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "greetings\n",
      "Bot :  Hello, I'm your helping bot\n",
      "You : what can you help me with ?\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "support\n",
      "Bot :  I can help you to book flight tickets easily\n",
      "You : well see ya\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "greetings\n",
      "Bot :  Hi there, how can I help you?\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    text = input(\"You : \")\n",
    "#     text = 'Hi'\n",
    "    print(\"Bot : \",bot_response(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
